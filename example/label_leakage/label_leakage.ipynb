{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dominant-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reverse-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aijack.attack import SplitNNNormAttack\n",
    "from aijack.collaborative import SplitNN, SplitNNClient\n",
    "from aijack.utils import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loved-saturday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"batch_size\":128\n",
    "}\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "visible-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      "    Total: 284807\n",
      "    Positive: 492 (0.17% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "raw_df_neg = raw_df[raw_df[\"Class\"] == 0]\n",
    "raw_df_pos = raw_df[raw_df[\"Class\"] == 1]\n",
    "\n",
    "down_df_neg = raw_df_neg#.sample(40000)\n",
    "down_df = pd.concat([down_df_neg, raw_df_pos])\n",
    "\n",
    "neg, pos = np.bincount(down_df['Class'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sonic-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = down_df.copy()\n",
    "\n",
    "# You don't want the `Time` column.\n",
    "cleaned_df.pop('Time')\n",
    "\n",
    "# The `Amount` column covers a huge range. Convert to log-space.\n",
    "eps = 0.001 # 0 => 0.1Â¢\n",
    "cleaned_df['Log Ammount'] = np.log(cleaned_df.pop('Amount')+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "natural-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle our dataset.\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mineral-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (182276,)\n",
      "Validation labels shape: (45569,)\n",
      "Test labels shape: (56962,)\n",
      "Training features shape: (182276, 29)\n",
      "Validation features shape: (45569, 29)\n",
      "Test features shape: (56962, 29)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sudden-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train_features,\n",
    "                        train_labels.astype(np.float64).reshape(-1, 1))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=config[\"batch_size\"],\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = DataSet(test_features,\n",
    "                       test_labels.astype(np.float64).reshape(-1, 1))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=config[\"batch_size\"],\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "combined-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 16\n",
    "\n",
    "class FirstNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FirstNet, self).__init__()        \n",
    "        self.L1 = nn.Linear(train_features.shape[-1],\n",
    "                            hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.L1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class SecondNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SecondNet, self).__init__()        \n",
    "        self.L2 = nn.Linear(hidden_dim,\n",
    "                            1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.L2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "def torch_auc(label, pred):\n",
    "    return roc_auc_score(label.detach().numpy(),\n",
    "                         pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "different-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = FirstNet()\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "model_2 = SecondNet()\n",
    "model_2 = model_2.to(device)\n",
    "\n",
    "model_1.double()\n",
    "model_2.double()\n",
    "\n",
    "opt_1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
    "opt_2 = optim.Adam(model_2.parameters(), lr=1e-3)\n",
    "optimizers = [opt_1, opt_2]\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "client_1 = SplitNNClient(model_1, user_id=0)\n",
    "client_2 = SplitNNClient(model_2, user_id=0)\n",
    "clients = [client_1, client_2]\n",
    "splitnn = SplitNN(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "smooth-compatibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006850520310244336 0.8585252918413027\n",
      "3.098145096120323e-05 0.94915664829526\n",
      "2.309489709589224e-05 0.9698619553985939\n"
     ]
    }
   ],
   "source": [
    "splitnn.train()\n",
    "for epoch in range(3):\n",
    "    epoch_loss = 0\n",
    "    epoch_outputs = []\n",
    "    epoch_labels = []\n",
    "    for i, data in enumerate(train_loader):\n",
    "        for opt in optimizers:\n",
    "            opt.zero_grad()\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = splitnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        splitnn.backward(outputs.grad)\n",
    "        epoch_loss += loss.item() / len(train_loader.dataset)\n",
    "        \n",
    "        epoch_outputs.append(outputs)\n",
    "        epoch_labels.append(labels)\n",
    "        \n",
    "        for opt in optimizers:\n",
    "            opt.step()\n",
    "        \n",
    "    print(epoch_loss, torch_auc(torch.cat(epoch_labels),\n",
    "                                torch.cat(epoch_outputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alone-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985719601333076"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nall = SplitNNNormAttack(splitnn)\n",
    "nall.attack(train_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-karen",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-heading",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
