{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "equal-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "from secureml.utils import DataSet\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "focused-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client(torch.nn.Module):\n",
    "    def __init__(self, model, user_id=0):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.user_id = user_id\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        return output\n",
    "\n",
    "    def upload(self):\n",
    "        return self.model.cpu().state_dict()\n",
    "\n",
    "    def download(self, model_parameters):\n",
    "        self.model.load_state_dict(model_parameters)\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "binary-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_list_to_tensor(model_params_list):\n",
    "    for k in model_params_list.keys():\n",
    "        model_params_list[k] = torch.from_numpy(\n",
    "            np.asarray(model_params_list[k])\n",
    "        ).float()\n",
    "    return model_params_list\n",
    "\n",
    "\n",
    "class Server:\n",
    "    def __init__(self, clients, global_model, servre_id=0):\n",
    "        self.clients = clients\n",
    "        self.servre_id = servre_id\n",
    "        self.num_clients = len(clients)\n",
    "        self.global_model = global_model\n",
    "\n",
    "    def update(self, weight=None):\n",
    "        if weight is None:\n",
    "            weight = np.ones(self.num_clients) / self.num_clients\n",
    "            \n",
    "        uploaded_parameters = [c.upload() for c in self.clients]\n",
    "        averaged_params = uploaded_parameters[0]\n",
    "        \n",
    "        for k in averaged_params.keys():\n",
    "            for i in range(0, len(uploaded_parameters)):\n",
    "                local_model_params = uploaded_parameters[i]\n",
    "                w = weight[i]\n",
    "                if i == 0:\n",
    "                    averaged_params[k] = local_model_params[k] * w\n",
    "                else:\n",
    "                    averaged_params[k] += local_model_params[k] * w\n",
    "                    \n",
    "        self.global_model.load_state_dict(averaged_params)\n",
    "\n",
    "    def distribtue(self):\n",
    "        for client in self.clients:\n",
    "            client.download(self.global_model.cpu().state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cognitive-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fla = nn.Flatten()\n",
    "        self.fc = nn.Linear(64*64, 40)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fla(x)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "light-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_Attack_Client(Client):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        target_label,\n",
    "        generator,\n",
    "        generator_optimizer,\n",
    "        generator_criterion,\n",
    "        nz=100,\n",
    "        user_id=0,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super().__init__(model, user_id=user_id)\n",
    "        self.target_label = target_label\n",
    "        self.generator = generator\n",
    "        self.generator_optimizer = generator_optimizer\n",
    "        self.generator_criterion = generator_criterion\n",
    "        self.nz = nz\n",
    "        self.device = device\n",
    "\n",
    "        self.discriminator = copy.deepcopy(model)\n",
    "\n",
    "    def update_generator(self, dataloader, epoch=1, log_interval=5):\n",
    "        for i in range(epoch):\n",
    "            running_error = 0\n",
    "            data_size = 0\n",
    "            for _, data in enumerate(dataloader, 0):\n",
    "                self.generator.zero_grad()\n",
    "                real_cpu = data[0].to(self.device)\n",
    "                b_size = real_cpu.size(0)\n",
    "                data_size += b_size\n",
    "                label = torch.full(\n",
    "                    (b_size,), self.target_label, dtype=torch.int64, device=self.device\n",
    "                )\n",
    "                noise = torch.randn(b_size, self.nz, 1, 1, device=self.device)\n",
    "                fake = self.generator(noise)\n",
    "                output = self.discriminator(fake)\n",
    "                loss_generator = self.generator_criterion(output, label)\n",
    "                loss_generator.backward()\n",
    "                self.generator_optimizer.step()\n",
    "\n",
    "                running_error += loss_generator.item()\n",
    "    \n",
    "            if i % log_interval == 0:\n",
    "                print(f\"{i} - {running_error/data_size}\")\n",
    "                \n",
    "    def attack(self, n):\n",
    "        noise = torch.randn(n, self.nz, 1, 1, device=self.device)\n",
    "        with torch.no_grad():\n",
    "            fake = self.generator(noise).view\n",
    "        return fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "attended-pillow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 64, 64])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "grand-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Code (from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, nc, ngf):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "viral-forge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "# Size of feature maps in generator\n",
    "ngf = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "numeric-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_t_dataset = fetch_olivetti_faces()        \n",
    "X = at_t_dataset[\"images\"]\n",
    "y = at_t_dataset[\"target\"]\n",
    "\n",
    "# ToTensor：画像のグレースケール化（RGBの0~255を0~1の範囲に正規化）、Normalize：Z値化（RGBの平均と標準偏差を0.5で決め打ちして正規化）\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "idx_1 = random.sample(range(400), 200)\n",
    "idx_2 = list(set(range(400)) - set(idx_1))\n",
    "\n",
    "global_trainset = DataSet(X, y, transform=transform)\n",
    "global_trainloader = torch.utils.data.DataLoader(global_trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "trainset_1 = DataSet(X[idx_1], y[idx_1], transform=transform)\n",
    "trainloader_1 = torch.utils.data.DataLoader(trainset_1, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "trainset_2 = DataSet(X[idx_2], y[idx_2], transform=transform)\n",
    "trainloader_2 = torch.utils.data.DataLoader(trainset_2, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "trainloaders = [trainloader_1, trainloader_2]\n",
    "dataset_nums = [200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thick-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = Net()\n",
    "client_1 = Client(net_1, user_id=0)\n",
    "optimizer_1 = optim.SGD(client_1.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "net_2 = Net()\n",
    "client_2 = Client(net_2, user_id=0)\n",
    "optimizer_2 = optim.SGD(client_2.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "clients = [client_1, client_2]\n",
    "optimizers = [optimizer_1, optimizer_2]\n",
    "\n",
    "server = Server(clients, Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confused-startup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0: client-1 0.9218211030960083\n",
      "epoch-0: client-2 0.9218912661075592\n",
      "epoch-1: client-1 0.9191890966892242\n",
      "epoch-1: client-2 0.918871500492096\n",
      "epoch-2: client-1 0.9106276357173919\n",
      "epoch-2: client-2 0.9120814323425293\n",
      "epoch-3: client-1 0.8939419567584992\n",
      "epoch-3: client-2 0.8967595267295837\n",
      "epoch-4: client-1 0.8772130262851715\n",
      "epoch-4: client-2 0.8802297163009644\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "client_num = 2\n",
    "\n",
    "for epoch in range(10): \n",
    "    for client_idx in range(client_num):\n",
    "        client = clients[client_idx]\n",
    "        trainloader = trainloaders[client_idx]\n",
    "        optimizer = optimizers[client_idx]\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = client(inputs)\n",
    "            loss = criterion(outputs, labels.to(torch.int64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"epoch-{epoch}: client-{client_idx+1}\",\n",
    "              running_loss / dataset_nums[client_idx])\n",
    "    \n",
    "    server.update()\n",
    "    server.distribtue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "integrated-there",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3325\n"
     ]
    }
   ],
   "source": [
    "in_preds = []\n",
    "in_label = []\n",
    "with torch.no_grad():\n",
    "        for data in global_trainloader:\n",
    "            inputs, labels = data\n",
    "            outputs = server.global_model(inputs)\n",
    "            in_preds.append(outputs)\n",
    "            in_label.append(labels)  \n",
    "        in_preds = torch.cat(in_preds)\n",
    "        in_label = torch.cat(in_label)\n",
    "\n",
    "print(accuracy_score(np.array(torch.argmax(in_preds, axis=1)),\n",
    "                     np.array(in_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "defined-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = Net()\n",
    "client_1 = Client(net_1, user_id=0)\n",
    "optimizer_1 = optim.SGD(client_1.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "net_2 = Net()\n",
    "generator = Generator(nz, nc, ngf)\n",
    "optimizer_g = optim.SGD(generator.parameters(), lr=0.02, momentum=0.9)\n",
    "target_label = 0\n",
    "client_2 = GAN_Attack_Client(net_2, target_label, generator,\n",
    "                             optimizer_g, criterion, user_id=0)\n",
    "optimizer_2 = optim.SGD(client_2.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "clients = [client_1, client_2]\n",
    "optimizers = [optimizer_1, optimizer_2]\n",
    "\n",
    "server = Server(clients, Net())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "binary-filling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch-0: client-1 0.9216112422943116\n",
      "epoch-0: client-2 0.9217164516448975\n",
      "0 - 3.69150710105896\n",
      "5 - 2.87933349609375\n",
      "10 - 2.745025396347046\n",
      "15 - 2.7356276512145996\n",
      "20 - 2.735330820083618\n",
      "25 - 2.734203815460205\n",
      "30 - 2.7334907054901123\n",
      "35 - 2.7332115173339844\n",
      "40 - 2.732907772064209\n",
      "45 - 2.7326292991638184\n",
      "epoch-1: client-1 0.9180269753932953\n",
      "epoch-1: client-2 0.9169635343551635\n",
      "0 - 2.7327988147735596\n",
      "5 - 2.7324399948120117\n",
      "10 - 2.7323176860809326\n",
      "15 - 2.7321436405181885\n",
      "20 - 2.732272148132324\n",
      "25 - 2.7319252490997314\n",
      "30 - 2.7320103645324707\n",
      "35 - 2.7319753170013428\n",
      "40 - 2.7317254543304443\n",
      "45 - 2.731830358505249\n",
      "epoch-2: client-1 0.9055757439136505\n",
      "epoch-2: client-2 0.9096765840053558\n",
      "0 - 2.7316672801971436\n",
      "5 - 2.731858015060425\n",
      "10 - 2.7319586277008057\n",
      "15 - 2.7317817211151123\n",
      "20 - 2.7317209243774414\n",
      "25 - 2.731722354888916\n",
      "30 - 2.731776237487793\n",
      "35 - 2.7317442893981934\n",
      "40 - 2.731635332107544\n",
      "45 - 2.7314648628234863\n",
      "epoch-3: client-1 0.8927387428283692\n",
      "epoch-3: client-2 0.8979940354824066\n",
      "0 - 2.731560230255127\n",
      "5 - 2.731628894805908\n",
      "10 - 2.7316067218780518\n",
      "15 - 2.7316176891326904\n",
      "20 - 2.7315728664398193\n",
      "25 - 2.7314772605895996\n",
      "30 - 2.731490135192871\n",
      "35 - 2.7314844131469727\n",
      "40 - 2.731412172317505\n",
      "45 - 2.7315146923065186\n",
      "epoch-4: client-1 0.8765245974063873\n",
      "epoch-4: client-2 0.8792023074626922\n",
      "0 - 2.731383800506592\n",
      "5 - 2.7313833236694336\n",
      "10 - 2.7314157485961914\n",
      "15 - 2.7313427925109863\n",
      "20 - 2.731450080871582\n",
      "25 - 2.731431007385254\n",
      "30 - 2.731426954269409\n",
      "35 - 2.731410026550293\n",
      "40 - 2.7314579486846924\n",
      "45 - 2.7313852310180664\n",
      "epoch-5: client-1 0.8528850364685059\n",
      "epoch-5: client-2 0.8608492863178253\n",
      "0 - 2.731335401535034\n",
      "5 - 2.7313642501831055\n",
      "10 - 2.731401205062866\n",
      "15 - 2.731304407119751\n",
      "20 - 2.7313578128814697\n",
      "25 - 2.731372117996216\n",
      "30 - 2.7313640117645264\n",
      "35 - 2.7313320636749268\n",
      "40 - 2.7313199043273926\n",
      "45 - 2.7313618659973145\n",
      "epoch-6: client-1 0.836150130033493\n",
      "epoch-6: client-2 0.8431511652469635\n",
      "0 - 2.7313222885131836\n",
      "5 - 2.7312769889831543\n",
      "10 - 2.7313179969787598\n",
      "15 - 2.7312889099121094\n",
      "20 - 2.7312822341918945\n",
      "25 - 2.7313175201416016\n",
      "30 - 2.7313103675842285\n",
      "35 - 2.7313084602355957\n",
      "40 - 2.7313268184661865\n",
      "45 - 2.731265068054199\n",
      "epoch-7: client-1 0.8252919375896454\n",
      "epoch-7: client-2 0.8287739157676697\n",
      "0 - 2.731321334838867\n",
      "5 - 2.7312498092651367\n",
      "10 - 2.7312514781951904\n",
      "15 - 2.731229066848755\n",
      "20 - 2.7312235832214355\n",
      "25 - 2.731220245361328\n",
      "30 - 2.731261968612671\n",
      "35 - 2.7312235832214355\n",
      "40 - 2.7312817573547363\n",
      "45 - 2.731217384338379\n",
      "epoch-8: client-1 0.8147873616218567\n",
      "epoch-8: client-2 0.8181192791461944\n",
      "0 - 2.731224536895752\n",
      "5 - 2.7312541007995605\n",
      "10 - 2.7312653064727783\n",
      "15 - 2.7311887741088867\n",
      "20 - 2.731245517730713\n",
      "25 - 2.7312841415405273\n",
      "30 - 2.731210231781006\n",
      "35 - 2.7312211990356445\n",
      "40 - 2.731199026107788\n",
      "45 - 2.731231212615967\n",
      "epoch-9: client-1 0.8063401472568512\n",
      "epoch-9: client-2 0.8114729869365692\n",
      "0 - 2.731154680252075\n",
      "5 - 2.7312467098236084\n",
      "10 - 2.731205463409424\n",
      "15 - 2.7312464714050293\n",
      "20 - 2.731189727783203\n",
      "25 - 2.731226921081543\n",
      "30 - 2.7311863899230957\n",
      "35 - 2.7311933040618896\n",
      "40 - 2.7311832904815674\n",
      "45 - 2.7312724590301514\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "client_num = 2\n",
    "adversary_client_id = 1\n",
    "\n",
    "for epoch in range(10): \n",
    "    for client_idx in range(client_num):\n",
    "        client = clients[client_idx]\n",
    "        trainloader = trainloaders[client_idx]\n",
    "        optimizer = optimizers[client_idx]\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = client(inputs)\n",
    "            loss = criterion(outputs, labels.to(torch.int64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"epoch-{epoch}: client-{client_idx+1}\",\n",
    "              running_loss / dataset_nums[client_idx])\n",
    "        \n",
    "        if client_idx == adversary_client_id:\n",
    "            client.update_generator(trainloader)\n",
    "    \n",
    "    server.update()\n",
    "    server.distribtue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "infrared-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_2.attack(1).reshape(64, 64).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "split-seeker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64 at 0x1E165DDF610>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(client_2.attack(1).reshape(64, 64).numpy(), mode=\"L\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
