{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-novelty",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT PATHS:\n",
    "BASE = 'data/'\n",
    "\n",
    "imgs = []\n",
    "labels = []\n",
    "for i in range(1, 41):\n",
    "    for j in range(1, 11):\n",
    "        img = cv2.imread(BASE + f's{i}/{j}.pgm', 0)\n",
    "        imgs.append(img)\n",
    "        labels.append(i-1)\n",
    "        \n",
    "X = np.stack(imgs)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    \"\"\"\n",
    "    This class allows you to convert numpy.array to torch.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        \"\"\"\n",
    "        Attriutes\n",
    "            x (np.array) :\n",
    "            y (np.array) :\n",
    "            transform (torch.transform)\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToTensor：画像のグレースケール化（RGBの0~255を0~1の範囲に正規化）、Normalize：Z値化（RGBの平均と標準偏差を0.5で決め打ちして正規化）\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                transforms.Normalize((0.5, ), (0.5, ))])\n",
    "\n",
    "trainset = DataSet(X, y, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fla = nn.Flatten()\n",
    "        #self.fc = nn.Linear(112*92, 40)\n",
    "        self.fc = nn.Linear(64*64, 40)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fla(x)\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        #train_loss = loss.item()\n",
    "        #print('[%d, %5d] loss: %.3f' %\n",
    "        #          (epoch + 1, i + 1, train_loss))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "in_preds = []\n",
    "in_label = []\n",
    "with torch.no_grad():\n",
    "        for data in trainloader:\n",
    "            inputs, labels = data\n",
    "            outputs = net(inputs)\n",
    "            in_preds.append(outputs)\n",
    "            in_label.append(labels)  \n",
    "        in_preds = torch.cat(in_preds)\n",
    "        in_label = torch.cat(in_label)  \n",
    "print(accuracy_score(np.array(torch.argmax(in_preds, axis=1)),\n",
    "                     np.array(in_label)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inversion(nn.Module):\n",
    "    def __init__(self, nc, ngf, nz, truncation, c):\n",
    "        super(Inversion, self).__init__()\n",
    "\n",
    "        self.nc = nc\n",
    "        self.ngf = ngf\n",
    "        self.nz = nz\n",
    "        self.truncation = truncation\n",
    "        self.c = c\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # input is Z\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.Tanh(),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.Tanh(),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.Tanh(),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.Tanh(),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        topk, indices = torch.topk(x, self.truncation)\n",
    "        topk = torch.clamp(torch.log(topk), min=-1000) + self.c\n",
    "        topk_min = topk.min(1, keepdim=True)[0]\n",
    "        topk = topk + F.relu(-topk_min)\n",
    "        x = torch.zeros(len(x), self.nz).scatter_(1, indices, topk)\n",
    "\n",
    "        x = x.view(-1, self.nz, 1, 1)\n",
    "        x = self.decoder(x)\n",
    "        x = x.view(-1, 1, 64, 64)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "inversion = Inversion(nc = 1, ngf = 128, nz = 530, truncation=40, c = 50)\n",
    "inversion = inversion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 10\n",
    "\n",
    "net.eval()\n",
    "inversion.train()\n",
    "\n",
    "optimizer = optimizer = optim.Adam(inversion.parameters(), lr=0.005, betas=(0.5, 0.999), amsgrad=True)\n",
    "\n",
    "epoch_loss = 0\n",
    "for epoch in range(30):\n",
    "  \n",
    "  for batch_idx, (data, target) in enumerate(trainloader):\n",
    "      data, target = data.to(device), target.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      with torch.no_grad():\n",
    "              prediction = net(data)\n",
    "      reconstruction = inversion(prediction)\n",
    "      loss = F.mse_loss(reconstruction, data)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      epoch_loss += loss.item()\n",
    "      if batch_idx % log_interval == 0:\n",
    "          print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(epoch,\n",
    "                                                              batch_idx * len(data),\n",
    "                                                              len(trainloader.dataset),\n",
    "                                                              epoch_loss / log_interval))\n",
    "          epoch_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data.cpu().detach().numpy()[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(reconstruction.cpu().detach().numpy()[2][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-prediction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
