{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SROAZ9dO80s8"
      },
      "source": [
        "# FedAVG\n",
        "\n",
        "In this tutorial, you will learn how to simulate FedAVG, representative scheme of Federated Learning, with AIJack. You can choose the single process or MPI as the backend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNMDQuH49CBO"
      },
      "source": [
        "## Single Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J4s0w9rHwOd8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from mpi4py import MPI\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
        "from aijack.collaborative.fedavg import FedAVGAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gsh_CjamwqfV"
      },
      "outputs": [],
      "source": [
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def prepare_dataloader(num_clients, myid, train=True, path=\"\"):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "    )\n",
        "    if train:\n",
        "        dataset = datasets.MNIST(path, train=True, download=True, transform=transform)\n",
        "        idxs = list(range(len(dataset.data)))\n",
        "        random.shuffle(idxs)\n",
        "        idx = np.array_split(idxs, num_clients, 0)[myid - 1]\n",
        "        dataset.data = dataset.data[idx]\n",
        "        dataset.targets = dataset.targets[idx]\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=training_batch_size\n",
        "        )\n",
        "        return train_loader\n",
        "    else:\n",
        "        dataset = datasets.MNIST(path, train=False, download=True, transform=transform)\n",
        "        test_loader = torch.utils.data.DataLoader(dataset, batch_size=test_batch_size)\n",
        "        return test_loader\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.ln = nn.Linear(28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln(x.reshape(-1, 28 * 28))\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UX-5FPlbxs4z"
      },
      "outputs": [],
      "source": [
        "training_batch_size = 64\n",
        "test_batch_size = 64\n",
        "num_rounds = 5\n",
        "lr = 0.001\n",
        "seed = 0\n",
        "client_size = 2\n",
        "criterion = F.nll_loss\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "fix_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "9593a116d90b4813950ab65267268ad2",
            "77c48fa6fbbc4ce1b6fe5d2692478dae",
            "f88dbb8f70d84434b296e7d828651b14",
            "4160c1d4b4ea453aa3568722217c4690",
            "550b9614ff5b47a3a09f6d61b390b1d6",
            "2d65774840de45428117e57938bae02c",
            "7b90829e62d345d8b0dfb04509f79dfd",
            "fbf5e10097c347c78c48a742607738ff",
            "53ee6fdd59b742f2a0f8fca851d3016e",
            "ae648105b31545fea8e15c7683203dd9",
            "345e7473970c4eb3a7b2ced1b82b9a57",
            "ee62f1db501c4264a76b1a62f48a7be9",
            "1091c9f58f8d4c64ae6f90ec42221ced",
            "44aa60060ec648debc2334110dddf2ec",
            "f39bd6bdb4e14c9789439e906bbf43a6",
            "1034bf75a49b45738f37e48ba3d3b450",
            "aadbecb8edc8489999632ed9863befdf",
            "4d12af4771c444c8a0d26b9823947805",
            "31f7c397dc4d4cea84cde7d0b352c7b2",
            "39439c0b576e449dbc71aa143a1473b5",
            "bc3d0630330841a9ab7186c77bc8b78b",
            "3e2f43e944a5412db641fb078990fc3f",
            "f9201d21f7064d75b4174d0d309c65bf",
            "ae614b87627240fcba7c93a452322adb",
            "5e567ac544d243a79db8ee6f8a700b05",
            "a7466c8f4b56470dbb2bd30b7501b584",
            "fd7acd8304054cbcac4327efb988575b",
            "376fc19cdac6469a9c9c6828dd075f01",
            "6a4e6266fe6548c6956f983d67386655",
            "3e12f79b9c9f4df0b619208ff6b98776",
            "c8970960cf904f089bdc2b263dde4385",
            "e51ddd7b5ca2417c882ee3824bea929d",
            "4096574643fb424fb244a2fbea3ac75b",
            "39ab6acaea554a3f80b9ae135bf28e66",
            "80599966b0974e538ea4a7ee15b8ef0c",
            "4006824773f444cbbe840a8807ac3eab",
            "d9230884d5664145aee2a39d6e429b62",
            "f23749eb92104627ace585cf6920d6ec",
            "c3dec35f56464d948064a5f9f7ca750c",
            "a453fe4ebfd34b019bd9e8d74d3ae058",
            "06c5e346163144298a141a20c4e778da",
            "d40273866c914f578e4e5c1d8f430941",
            "b6dbf9b70d534db18aa2853a33626152",
            "8f4b1efa44ba415fb9af0f4404a2352c"
          ]
        },
        "id": "zz_YjoioAcLD",
        "outputId": "903d8cbb-dca4-421d-a6af-750d199ffaf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9593a116d90b4813950ab65267268ad2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee62f1db501c4264a76b1a62f48a7be9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9201d21f7064d75b4174d0d309c65bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39ab6acaea554a3f80b9ae135bf28e66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "local_dataloaders = [prepare_dataloader(client_size, c) for c in range(client_size)]\n",
        "test_dataloader = prepare_dataloader(client_size, -1, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEzYT3tex0Nm",
        "outputId": "801c7c0e-c9a8-4d75-d0c1-8ecf82f138bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round: 1, Test set: Average loss: 0.7824367607116699, Accuracy: 83.71\n",
            "Round: 2, Test set: Average loss: 0.5854546638488769, Accuracy: 86.49\n",
            "Round: 3, Test set: Average loss: 0.5077689335346222, Accuracy: 87.54\n",
            "Round: 4, Test set: Average loss: 0.4647755696773529, Accuracy: 88.25\n",
            "Round: 5, Test set: Average loss: 0.4369198709487915, Accuracy: 88.63\n"
          ]
        }
      ],
      "source": [
        "clients = [FedAvgClient(Net().to(device), user_id=c) for c in range(client_size)]\n",
        "local_optimizers = [optim.SGD(client.parameters(), lr=lr) for client in clients]\n",
        "\n",
        "server = FedAvgServer(clients, Net().to(device))\n",
        "\n",
        "for round in range(1, num_rounds + 1):\n",
        "  for client, local_trainloader, local_optimizer in zip(clients, local_dataloaders, local_optimizers):\n",
        "      for data in local_trainloader:\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          local_optimizer.zero_grad()\n",
        "          outputs = client(inputs)\n",
        "          loss = criterion(outputs, labels.to(torch.int64))\n",
        "          client.backward(loss)\n",
        "          local_optimizer.step()\n",
        "  server.action()\n",
        "\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_dataloader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = server(data)\n",
        "          test_loss += F.nll_loss(\n",
        "              output, target, reduction=\"sum\"\n",
        "          ).item()  # sum up batch loss\n",
        "          pred = output.argmax(\n",
        "              dim=1, keepdim=True\n",
        "          )  # get the index of the max log-probability\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_dataloader.dataset)\n",
        "  accuracy = 100.0 * correct / len(test_dataloader.dataset)\n",
        "  print(\n",
        "      f\"Round: {round}, Test set: Average loss: {test_loss}, Accuracy: {accuracy}\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkWsPf49FYv0"
      },
      "source": [
        "### Federated Learning with Paillier Encryption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE9boSiRoKWq",
        "outputId": "26641a32-c6ed-4ac1-c8f0-448b167db4d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/aijack/defense/paillier/torch_wrapper.py:70: RuntimeWarning: invalid value encountered in add\n",
            "  input._paillier_np_array + other.detach().cpu().numpy()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round: 1, Test set: Average loss: 0.5059196502208709, Accuracy: 84.52\n",
            "Round: 2, Test set: Average loss: 0.44262871532440184, Accuracy: 87.33\n",
            "Round: 3, Test set: Average loss: 0.40395034172534944, Accuracy: 88.34\n",
            "Round: 4, Test set: Average loss: 0.3897844295024872, Accuracy: 89.0\n",
            "Round: 5, Test set: Average loss: 0.3705228189945221, Accuracy: 89.22\n"
          ]
        }
      ],
      "source": [
        "from aijack.defense import PaillierGradientClientManager, PaillierKeyGenerator\n",
        "\n",
        "keygenerator = PaillierKeyGenerator(64)\n",
        "pk, sk = keygenerator.generate_keypair()\n",
        "\n",
        "manager = PaillierGradientClientManager(pk, sk)\n",
        "PaillierGradFedAvgClient = manager.attach(FedAvgClient)\n",
        "\n",
        "clients = [PaillierGradFedAvgClient(Net().to(device), user_id=c, server_side_update=False) for c in range(client_size)]\n",
        "local_optimizers = [optim.SGD(client.parameters(), lr=lr) for client in clients]\n",
        "\n",
        "server = FedAvgServer(clients, Net().to(device), server_side_update=False)\n",
        "\n",
        "for round in range(1, num_rounds + 1):\n",
        "  for client, local_trainloader, local_optimizer in zip(clients, local_dataloaders, local_optimizers):\n",
        "      for data in local_trainloader:\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "          local_optimizer.zero_grad()\n",
        "          outputs = client(inputs)\n",
        "          loss = criterion(outputs, labels.to(torch.int64))\n",
        "          client.backward(loss)\n",
        "          local_optimizer.step()\n",
        "  server.action()\n",
        "\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for data, target in test_dataloader:\n",
        "          data, target = data.to(device), target.to(device)\n",
        "          output = clients[0](data)\n",
        "          test_loss += F.nll_loss(\n",
        "              output, target, reduction=\"sum\"\n",
        "          ).item()  # sum up batch loss\n",
        "          pred = output.argmax(\n",
        "              dim=1, keepdim=True\n",
        "          )  # get the index of the max log-probability\n",
        "          correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_dataloader.dataset)\n",
        "  accuracy = 100.0 * correct / len(test_dataloader.dataset)\n",
        "  print(\n",
        "      f\"Round: {round}, Test set: Average loss: {test_loss}, Accuracy: {accuracy}\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fif8FXrHrv4s",
        "outputId": "3b870a11-4e38-4998-817c-52ce1c51da9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round: 5, Test set: Average loss: 0.3705228189945221, Accuracy: 89.22\n"
          ]
        }
      ],
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = clients[0](data)\n",
        "        test_loss += F.nll_loss(\n",
        "            output, target, reduction=\"sum\"\n",
        "        ).item()  # sum up batch loss\n",
        "        pred = output.argmax(\n",
        "            dim=1, keepdim=True\n",
        "        )  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_dataloader.dataset)\n",
        "accuracy = 100.0 * correct / len(test_dataloader.dataset)\n",
        "print(\n",
        "    f\"Round: {round}, Test set: Average loss: {test_loss}, Accuracy: {accuracy}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smTKPDVx9Dt4"
      },
      "source": [
        "## MPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzKLDKNw820p",
        "outputId": "844ceb9a-e90b-4d9b-cced-bd57e0c96ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi_fedavg.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi_fedavg.py\n",
        "import random\n",
        "from logging import getLogger\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from mpi4py import MPI\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
        "from aijack.collaborative.fedavg import MPIFedAVGAPI, MPIFedAvgClient, MPIFedAvgServer\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "\n",
        "training_batch_size = 64\n",
        "test_batch_size = 64\n",
        "num_rounds = 5\n",
        "lr = 0.001\n",
        "seed = 0\n",
        "\n",
        "\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def prepare_dataloader(num_clients, myid, train=True, path=\"\"):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "    )\n",
        "    if train:\n",
        "        dataset = datasets.MNIST(path, train=True, download=False, transform=transform)\n",
        "        idxs = list(range(len(dataset.data)))\n",
        "        random.shuffle(idxs)\n",
        "        idx = np.array_split(idxs, num_clients, 0)[myid - 1]\n",
        "        dataset.data = dataset.data[idx]\n",
        "        dataset.targets = dataset.targets[idx]\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=training_batch_size\n",
        "        )\n",
        "        return train_loader\n",
        "    else:\n",
        "        dataset = datasets.MNIST(path, train=False, download=False, transform=transform)\n",
        "        test_loader = torch.utils.data.DataLoader(dataset, batch_size=test_batch_size)\n",
        "        return test_loader\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.ln = nn.Linear(28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln(x.reshape(-1, 28 * 28))\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def evaluate_gloal_model(dataloader):\n",
        "    def _evaluate_global_model(api):\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloader:\n",
        "                data, target = data.to(api.device), target.to(api.device)\n",
        "                output = api.party.server(data)\n",
        "                test_loss += F.nll_loss(\n",
        "                    output, target, reduction=\"sum\"\n",
        "                ).item()  # sum up batch loss\n",
        "                pred = output.argmax(\n",
        "                    dim=1, keepdim=True\n",
        "                )  # get the index of the max log-probability\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(dataloader.dataset)\n",
        "        accuracy = 100.0 * correct / len(dataloader.dataset)\n",
        "        print(\n",
        "            f\"Round: {api.party.round}, Test set: Average loss: {test_loss}, Accuracy: {accuracy}\"\n",
        "        )\n",
        "\n",
        "    return _evaluate_global_model\n",
        "\n",
        "\n",
        "def main():\n",
        "    fix_seed(seed)\n",
        "\n",
        "    comm = MPI.COMM_WORLD\n",
        "    myid = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = Net()\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    if myid == 0:\n",
        "        dataloader = prepare_dataloader(size - 1, myid, train=False)\n",
        "        client_ids = list(range(1, size))\n",
        "        server = MPIFedAvgServer(comm, FedAvgServer([1, 2], model))\n",
        "        api = MPIFedAVGAPI(\n",
        "            comm,\n",
        "            server,\n",
        "            True,\n",
        "            F.nll_loss,\n",
        "            None,\n",
        "            None,\n",
        "            num_rounds,\n",
        "            1,\n",
        "            custom_action=evaluate_gloal_model(dataloader),\n",
        "            device=device\n",
        "        )\n",
        "    else:\n",
        "        dataloader = prepare_dataloader(size - 1, myid, train=True)\n",
        "        client = MPIFedAvgClient(comm, FedAvgClient(model, user_id=myid))\n",
        "        api = MPIFedAVGAPI(\n",
        "            comm,\n",
        "            client,\n",
        "            False,\n",
        "            F.nll_loss,\n",
        "            optimizer,\n",
        "            dataloader,\n",
        "            num_rounds,\n",
        "            1,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    api.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDBFHwAsvCv3",
        "outputId": "8e9a0f9d-0983-4a06-ead8-9924accd6334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round: 1, Test set: Average loss: 0.7860309104919434, Accuracy: 82.72\n",
            "Round: 2, Test set: Average loss: 0.5885528886795044, Accuracy: 86.04\n",
            "Round: 3, Test set: Average loss: 0.5102099328994751, Accuracy: 87.33\n",
            "Round: 4, Test set: Average loss: 0.4666414333820343, Accuracy: 88.01\n",
            "Round: 5, Test set: Average loss: 0.4383064950466156, Accuracy: 88.65\n"
          ]
        }
      ],
      "source": [
        "!mpiexec -np 3 --allow-run-as-root python /content/mpi_fedavg.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gb-Bks1FKD5"
      },
      "source": [
        "### MPI + Sparse Gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEv5pT_ABsPt",
        "outputId": "f916489c-c2c6-49ac-ef54-7ec96bf979ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi_fedavg_sparse.py\n"
          ]
        }
      ],
      "source": [
        " %%writefile mpi_fedavg_sparse.py\n",
        "import random\n",
        "from logging import getLogger\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from mpi4py import MPI\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
        "from aijack.collaborative.fedavg import MPIFedAVGAPI, MPIFedAvgClient, MPIFedAvgServer\n",
        "from aijack.defense.sparse import SparseGradientClientManager, SparseGradientServerManager\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "\n",
        "training_batch_size = 64\n",
        "test_batch_size = 64\n",
        "num_rounds = 5\n",
        "lr = 0.001\n",
        "seed = 0\n",
        "\n",
        "\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def prepare_dataloader(num_clients, myid, train=True, path=\"\"):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "    )\n",
        "    if train:\n",
        "        dataset = datasets.MNIST(path, train=True, download=False, transform=transform)\n",
        "        idxs = list(range(len(dataset.data)))\n",
        "        random.shuffle(idxs)\n",
        "        idx = np.array_split(idxs, num_clients, 0)[myid - 1]\n",
        "        dataset.data = dataset.data[idx]\n",
        "        dataset.targets = dataset.targets[idx]\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=training_batch_size\n",
        "        )\n",
        "        return train_loader\n",
        "    else:\n",
        "        dataset = datasets.MNIST(path, train=False, download=False, transform=transform)\n",
        "        test_loader = torch.utils.data.DataLoader(dataset, batch_size=test_batch_size)\n",
        "        return test_loader\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.ln = nn.Linear(28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln(x.reshape(-1, 28 * 28))\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def evaluate_gloal_model(dataloader):\n",
        "    def _evaluate_global_model(api):\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloader:\n",
        "                data, target = data.to(api.device), target.to(api.device)\n",
        "                output = api.party.server(data)\n",
        "                test_loss += F.nll_loss(\n",
        "                    output, target, reduction=\"sum\"\n",
        "                ).item()  # sum up batch loss\n",
        "                pred = output.argmax(\n",
        "                    dim=1, keepdim=True\n",
        "                )  # get the index of the max log-probability\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(dataloader.dataset)\n",
        "        accuracy = 100.0 * correct / len(dataloader.dataset)\n",
        "        print(\n",
        "            f\"Round: {api.party.round}, Test set: Average loss: {test_loss}, Accuracy: {accuracy}\"\n",
        "        )\n",
        "\n",
        "    return _evaluate_global_model\n",
        "\n",
        "\n",
        "def main():\n",
        "    fix_seed(seed)\n",
        "\n",
        "    comm = MPI.COMM_WORLD\n",
        "    myid = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = Net()\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    client_manager = SparseGradientClientManager(k=0.03)\n",
        "    SparseGradientFedAvgClient = client_manager.attach(FedAvgClient)\n",
        "\n",
        "    server_manager = SparseGradientServerManager()\n",
        "    SparseGradientFedAvgServer = server_manager.attach(FedAvgServer)\n",
        "\n",
        "    if myid == 0:\n",
        "        dataloader = prepare_dataloader(size - 1, myid, train=False)\n",
        "        client_ids = list(range(1, size))\n",
        "        server = MPIFedAvgServer(comm, SparseGradientFedAvgServer([1, 2], model))\n",
        "        api = MPIFedAVGAPI(\n",
        "            comm,\n",
        "            server,\n",
        "            True,\n",
        "            F.nll_loss,\n",
        "            None,\n",
        "            None,\n",
        "            num_rounds,\n",
        "            1,\n",
        "            custom_action=evaluate_gloal_model(dataloader),\n",
        "            device=device\n",
        "        )\n",
        "    else:\n",
        "        dataloader = prepare_dataloader(size - 1, myid, train=True)\n",
        "        client = MPIFedAvgClient(comm, SparseGradientFedAvgClient(model, user_id=myid))\n",
        "        api = MPIFedAVGAPI(\n",
        "            comm,\n",
        "            client,\n",
        "            False,\n",
        "            F.nll_loss,\n",
        "            optimizer,\n",
        "            dataloader,\n",
        "            num_rounds,\n",
        "            1,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    api.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9xKbw0_eDSD",
        "outputId": "4f846a20-83b5-46b4-ff66-938f10218837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Round: 1, Test set: Average loss: 1.7728474597930908, Accuracy: 38.47\n",
            "Round: 2, Test set: Average loss: 1.4043720769882202, Accuracy: 60.5\n",
            "Round: 3, Test set: Average loss: 1.1684634439468384, Accuracy: 70.27\n",
            "Round: 4, Test set: Average loss: 1.0258800836563111, Accuracy: 75.0\n",
            "Round: 5, Test set: Average loss: 0.9197616576194764, Accuracy: 77.6\n"
          ]
        }
      ],
      "source": [
        "!mpiexec -np 3 --allow-run-as-root python /content/mpi_fedavg_sparse.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "caa2b01f75ba60e629eaa9e4dabde0c46b243c9a0484934eeb17ad8b3fc9c91a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}