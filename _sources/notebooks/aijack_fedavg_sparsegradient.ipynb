{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SROAZ9dO80s8"
      },
      "source": [
        "# FedAVG with Sparse Gradient\n",
        "\n",
        "Federated Learning with sparse gradient is a technique that aims to reduce the amount of data exchanged between clients and the central server during the training process, while still maintaining the accuracy of the global model. In this technique, each client only sends a sparse representation of the gradient calculated on its local data to the server, rather than the full gradient. This reduces the amount of data that needs to be exchanged, which can be especially useful in situations where the data is sensitive or the communication bandwidth is limited.\n",
        "\n",
        "The sparse representation of the gradient can be achieved by applying a sparsifying transformation, such as thresholding or quantization, to the gradients before sending them to the server. The server then aggregates the sparse gradients and applies the inverse transformation to obtain the full gradients. In this tutorial, we adop top-k sparse gradient, where each client only sends the top-k largest absolute values of the gradient to the server.\n",
        "\n",
        "This approach can be beneficial in terms of privacy and communication efficiency, but it could also decrease the performance of the model. Furthermore, the sparsity of the gradients needs to be balanced with the accuracy of the model, as too much sparsity will result in a less accurate model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rBcj83n2wkH"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J4s0w9rHwOd8"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "idlkuHjjULVz"
      },
      "outputs": [],
      "source": [
        "training_batch_size = 64\n",
        "test_batch_size = 64\n",
        "seed = 0\n",
        "client_size = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gsh_CjamwqfV"
      },
      "outputs": [],
      "source": [
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def prepare_dataloader(num_clients, myid, train=True, path=\"\"):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "    )\n",
        "    if train:\n",
        "        dataset = datasets.MNIST(path, train=True, download=True, transform=transform)\n",
        "        idxs = list(range(len(dataset.data)))\n",
        "        random.shuffle(idxs)\n",
        "        idx = np.array_split(idxs, num_clients, 0)[myid - 1]\n",
        "        dataset.data = dataset.data[idx]\n",
        "        dataset.targets = dataset.targets[idx]\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=training_batch_size\n",
        "        )\n",
        "        return train_loader\n",
        "    else:\n",
        "        dataset = datasets.MNIST(path, train=False, download=True, transform=transform)\n",
        "        test_loader = torch.utils.data.DataLoader(dataset, batch_size=test_batch_size)\n",
        "        return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UX-5FPlbxs4z"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "fix_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "7b39acb30b084409946cf0ad06f943c6",
            "2361b65712904536bf13ebfc9cb66362",
            "cfcb525ca53348479d07f84dff4f2c06",
            "cf054dca836e44c598b4bdcadaa8bd73",
            "66b327dba4dd41b7a508814843f5a85e",
            "f32c0c3f07684af78058f4bdb74b92c7",
            "ed4a34abc2ab49eaa3c19d43512dae7e",
            "11d98e0a14b44ba499cc60c35345dea3",
            "98c2aabcc1cf412aab328a2204a4c93e",
            "c871505ed1dd411d85ef271d75f5ba32",
            "4e9053963cfa4277b6221d6b05e87ed2",
            "27d32fd0768d4ed28558ec76732e183d",
            "9e21cb3582ab4d8098daa15b5f3a56f6",
            "ec49f40d097e40d9949753ea2a5ea2dd",
            "c1412ba8e5ed4244a5581b583b8aa100",
            "ffa03102b94940188ddab0dfac6df130",
            "dcd883f06d474997913e4ff274809944",
            "faf54b65242e45bc968b62bcb358edb3",
            "874b9fb270144d91a0071c76e735ee2e",
            "883fc12a8a244b228efe6b5a1857045c",
            "56c8f183389b4836847ffda22a9349d0",
            "e1da371859ef4d8688fffb82f3b637d5",
            "8212c3a6c46e475d91727237c277b10d",
            "cde361e3a34e4db5b05b7e4ef594012f",
            "5c2f77f1d68448e4b209f89eb035927c",
            "93dfeb7e363d40ddb837840693dc4514",
            "c8aca95a466c435faceb8176b6d81f36",
            "6b63bf63b3774547b4a5e1359b7b1bde",
            "5a032e084d6b4dcf9e775d3f0381345f",
            "1af51784b0b143d7ba50cf27615a5322",
            "5f2ac94231344ec9a46efd79ca2af641",
            "bf3401aa84814b01b080637e5abcb22b",
            "e147a1e466a54a3fb2b5c474cfa37153",
            "9f45b454f7e745a8a33bcd303505f048",
            "03c4d157135242c8b3cf1bfebfd9fc73",
            "fe16c867e8ad44aba19534d4a4ec9fbe",
            "c363c0f4409243c680964f640f3d221f",
            "6ec0fefc5db5433f8156b3762d7ba135",
            "9da2a07b9ad54100a17103bd86a7e07f",
            "8524811085124d5ab15b144bf5469a79",
            "3a4ef9dc55a7486d857255013eb18421",
            "3d2cc086598f4b92b621f759c1e62d5c",
            "c828fa6fd9ce47ce945e319336db6c4f",
            "b58aefe917604ee7910f8bb2641248b4"
          ]
        },
        "id": "zz_YjoioAcLD",
        "outputId": "9ca9f5e1-1f1c-4446-ddb9-b552768c93a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b39acb30b084409946cf0ad06f943c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27d32fd0768d4ed28558ec76732e183d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8212c3a6c46e475d91727237c277b10d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f45b454f7e745a8a33bcd303505f048",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "local_dataloaders = [prepare_dataloader(client_size, c) for c in range(client_size)]\n",
        "test_dataloader = prepare_dataloader(client_size, -1, train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzHnnoTm2zbX"
      },
      "source": [
        "## Top-K Sparse Gradient with MPI backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEv5pT_ABsPt",
        "outputId": "feab113f-076b-47c2-de48-595d5b4c91d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mpi_FedAVG_sparse.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile mpi_FedAVG_sparse.py\n",
        "import random\n",
        "from logging import getLogger\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from mpi4py import MPI\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from aijack.collaborative import FedAVGClient, FedAVGServer, MPIFedAVGAPI, MPIFedAVGClientManager, MPIFedAVGServerManager\n",
        "from aijack.defense.sparse import (\n",
        "    SparseGradientClientManager,\n",
        "    SparseGradientServerManager,\n",
        ")\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "\n",
        "training_batch_size = 64\n",
        "test_batch_size = 64\n",
        "num_rounds = 5\n",
        "lr = 0.001\n",
        "seed = 0\n",
        "\n",
        "\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def prepare_dataloader(num_clients, myid, train=True, path=\"\"):\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "    )\n",
        "    if train:\n",
        "        dataset = datasets.MNIST(path, train=True, download=False, transform=transform)\n",
        "        idxs = list(range(len(dataset.data)))\n",
        "        random.shuffle(idxs)\n",
        "        idx = np.array_split(idxs, num_clients, 0)[myid - 1]\n",
        "        dataset.data = dataset.data[idx]\n",
        "        dataset.targets = dataset.targets[idx]\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            dataset, batch_size=training_batch_size\n",
        "        )\n",
        "        return train_loader\n",
        "    else:\n",
        "        dataset = datasets.MNIST(path, train=False, download=False, transform=transform)\n",
        "        test_loader = torch.utils.data.DataLoader(dataset, batch_size=test_batch_size)\n",
        "        return test_loader\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.ln = nn.Linear(28 * 28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ln(x.reshape(-1, 28 * 28))\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def evaluate_gloal_model(dataloader):\n",
        "    def _evaluate_global_model(api):\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloader:\n",
        "                data, target = data.to(api.device), target.to(api.device)\n",
        "                output = api.party(data)\n",
        "                test_loss += F.nll_loss(\n",
        "                    output, target, reduction=\"sum\"\n",
        "                ).item()  # sum up batch loss\n",
        "                pred = output.argmax(\n",
        "                    dim=1, keepdim=True\n",
        "                )  # get the index of the max log-probability\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(dataloader.dataset)\n",
        "        accuracy = 100.0 * correct / len(dataloader.dataset)\n",
        "        print(\n",
        "            f\"Round: {api.party.round}, Test set: Average loss: {test_loss}, Accuracy: {accuracy}\"\n",
        "        )\n",
        "\n",
        "    return _evaluate_global_model\n",
        "\n",
        "\n",
        "def main():\n",
        "    fix_seed(seed)\n",
        "\n",
        "    comm = MPI.COMM_WORLD\n",
        "    myid = comm.Get_rank()\n",
        "    size = comm.Get_size()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = Net()\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    sg_client_manager = SparseGradientClientManager(k=0.03)\n",
        "    mpi_client_manager = MPIFedAVGClientManager()\n",
        "    SparseGradientFedAVGClient = sg_client_manager.attach(FedAVGClient)\n",
        "    MPISparseGradientFedAVGClient = mpi_client_manager.attach(SparseGradientFedAVGClient)\n",
        "\n",
        "    sg_server_manager = SparseGradientServerManager()\n",
        "    mpi_server_manager = MPIFedAVGServerManager()\n",
        "    SparseGradientFedAVGServer = sg_server_manager.attach(FedAVGServer)\n",
        "    MPISparseGradientFedAVGServer = mpi_server_manager.attach(SparseGradientFedAVGServer)\n",
        "\n",
        "    if myid == 0:\n",
        "        dataloader = prepare_dataloader(size - 1, myid, train=False)\n",
        "        client_ids = list(range(1, size))\n",
        "        server = MPISparseGradientFedAVGServer(comm, [1, 2], model)\n",
        "        api = MPIFedAVGAPI(\n",
        "            comm,\n",
        "            server,\n",
        "            True,\n",
        "            F.nll_loss,\n",
        "            None,\n",
        "            None,\n",
        "            num_rounds,\n",
        "            1,\n",
        "            custom_action=evaluate_gloal_model(dataloader),\n",
        "            device=device,\n",
        "        )\n",
        "    else:\n",
        "        dataloader = prepare_dataloader(size - 1, myid, train=True)\n",
        "        client = MPISparseGradientFedAVGClient(comm, model, user_id=myid)\n",
        "        api = MPIFedAVGAPI(\n",
        "            comm,\n",
        "            client,\n",
        "            False,\n",
        "            F.nll_loss,\n",
        "            optimizer,\n",
        "            dataloader,\n",
        "            num_rounds,\n",
        "            1,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "    api.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9xKbw0_eDSD",
        "outputId": "d9bc03b4-2608-4605-8f77-6b3d52b3d83c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "communication 0, epoch 0: client-2 0.02008056694070498\n",
            "communication 0, epoch 0: client-3 0.019996537216504413\n",
            "Round: 1, Test set: Average loss: 1.7728474597930908, Accuracy: 38.47\n",
            "communication 1, epoch 0: client-3 0.016255500958363214\n",
            "communication 1, epoch 0: client-2 0.016343721010287603\n",
            "Round: 2, Test set: Average loss: 1.4043720769882202, Accuracy: 60.5\n",
            "communication 2, epoch 0: client-2 0.014353630113601685\n",
            "communication 2, epoch 0: client-3 0.014260987114906311\n",
            "Round: 3, Test set: Average loss: 1.1684634439468384, Accuracy: 70.27\n",
            "communication 3, epoch 0: client-2 0.013123111790418624\n",
            "communication 3, epoch 0: client-3 0.013032549581925075\n",
            "Round: 4, Test set: Average loss: 1.0258800836563111, Accuracy: 75.0\n",
            "communication 4, epoch 0: client-2 0.012242827371756236\n",
            "communication 4, epoch 0: client-3 0.012150899289051692\n",
            "Round: 5, Test set: Average loss: 0.9197616576194764, Accuracy: 77.6\n"
          ]
        }
      ],
      "source": [
        "!sudo mpiexec -np 3 --allow-run-as-root python /content/mpi_FedAVG_sparse.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nBPih2JPaxPJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "caa2b01f75ba60e629eaa9e4dabde0c46b243c9a0484934eeb17ad8b3fc9c91a"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
