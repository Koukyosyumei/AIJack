{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Split Learning and Label Leakage"
      ],
      "metadata": {
        "id": "BuyM4I2f-FrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from aijack.attack import NormAttackManager\n",
        "from aijack.collaborative import SplitNN, SplitNNClient\n",
        "from aijack.utils import NumpyDataset"
      ],
      "metadata": {
        "id": "48I_xRo9-Hez"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FirstNet(nn.Module):\n",
        "    def __init__(self, train_features):\n",
        "        super(FirstNet, self).__init__()\n",
        "        self.L1 = nn.Linear(train_features.shape[-1], hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.L1(x)\n",
        "        x = nn.functional.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SecondNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SecondNet, self).__init__()\n",
        "        self.L2 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.L2(x)\n",
        "        x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "c6HcMly6_Yq9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters and Pre-processing"
      ],
      "metadata": {
        "id": "l3jrDrel_zsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "hidden_dim = 16\n",
        "num_communication = 2\n",
        "torch.manual_seed(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuqeDaJd_aEB",
        "outputId": "e2edb248-a978-4e55-ab81-67e753ca21f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8e513eb790>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_csv(\n",
        "        \"https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv\"\n",
        "    )\n",
        "raw_df_neg = raw_df[raw_df[\"Class\"] == 0]\n",
        "raw_df_pos = raw_df[raw_df[\"Class\"] == 1]\n",
        "\n",
        "down_df_neg = raw_df_neg  # .sample(40000)\n",
        "down_df = pd.concat([down_df_neg, raw_df_pos])\n",
        "\n",
        "neg, pos = np.bincount(down_df[\"Class\"])\n",
        "total = neg + pos\n",
        "print(\n",
        "    \"Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n\".format(\n",
        "        total, pos, 100 * pos / total\n",
        "    )\n",
        ")\n",
        "\n",
        "cleaned_df = down_df.copy()\n",
        "# You don't want the `Time` column.\n",
        "cleaned_df.pop(\"Time\")\n",
        "# The `Amount` column covers a huge range. Convert to log-space.\n",
        "eps = 0.001  # 0 => 0.1Â¢\n",
        "cleaned_df[\"Log Ammount\"] = np.log(cleaned_df.pop(\"Amount\") + eps)\n",
        "\n",
        "# Use a utility from sklearn to split and shuffle our dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop(\"Class\"))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "train_features = np.clip(train_features, -5, 5)\n",
        "\n",
        "train_dataset = NumpyDataset(\n",
        "    train_features, train_labels.astype(np.float64).reshape(-1, 1)\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCvh_MAW_j8O",
        "outputId": "81821d7d-42af-4a5e-f0f0-29c23c475924"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples:\n",
            "    Total: 284807\n",
            "    Positive: 492 (0.17% of total)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Learning"
      ],
      "metadata": {
        "id": "bopA4CdS_4-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = FirstNet(train_features)\n",
        "model_2 = SecondNet()\n",
        "model_1.double()\n",
        "model_2.double()\n",
        "opt_1 = optim.Adam(model_1.parameters(), lr=1e-3)\n",
        "opt_2 = optim.Adam(model_2.parameters(), lr=1e-3)\n",
        "optimizers = [opt_1, opt_2]\n",
        "client_1 = SplitNNClient(model_1, user_id=0)\n",
        "client_2 = SplitNNClient(model_2, user_id=0)\n",
        "clients = [client_1, client_2]\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "manager = NormAttackManager(criterion, device=\"cpu\")\n",
        "NormAttackSplitNN = manager.attach(SplitNN)\n",
        "normattacksplitnn = NormAttackSplitNN(clients, optimizers)\n",
        "\n",
        "normattacksplitnn.train()\n",
        "loss_log = []\n",
        "for _ in range(num_communication):\n",
        "    for data in train_loader:\n",
        "        inputs, labels = data\n",
        "        normattacksplitnn.zero_grad()\n",
        "        outputs = normattacksplitnn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        normattacksplitnn.backward(loss)\n",
        "        normattacksplitnn.step()\n",
        "        loss_log.append(loss.item())"
      ],
      "metadata": {
        "id": "O4o0y-tb_uwF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Norm-based Label Leakage Attack"
      ],
      "metadata": {
        "id": "oy2i88aU_6nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_leak_auc = normattacksplitnn.attack(train_loader)\n",
        "print(\"Leau AUC is \", train_leak_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKK3FQLN_xY7",
        "outputId": "c438cc7a-13c7-4b8e-a70d-b89b308147a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leau AUC is  0.9988736647330452\n"
          ]
        }
      ]
    }
  ]
}